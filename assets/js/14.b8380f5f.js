(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{202:function(e,a,t){"use strict";t.r(a);var r=t(3),s=Object(r.a)({},(function(){var e=this,a=e.$createElement,t=e._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"clickhouse-sinker"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#clickhouse-sinker"}},[e._v("#")]),e._v(" clickhouse_sinker")]),e._v(" "),t("p",[t("a",{attrs:{href:"https://travis-ci.com/housepower/clickhouse_sinker",target:"_blank",rel:"noopener noreferrer"}},[t("img",{attrs:{src:"https://travis-ci.com/housepower/clickhouse_sinker.svg?branch=master",alt:"Build Status"}}),t("OutboundLink")],1),e._v(" "),t("a",{attrs:{href:"https://goreportcard.com/report/github.com/housepower/clickhouse_sinker",target:"_blank",rel:"noopener noreferrer"}},[t("img",{attrs:{src:"https://goreportcard.com/badge/github.com/housepower/clickhouse_sinker",alt:"Go Report Card"}}),t("OutboundLink")],1)]),e._v(" "),t("p",[e._v("clickhouse_sinker is a sinker program that transfer kafka message into "),t("a",{attrs:{href:"https://clickhouse.yandex/",target:"_blank",rel:"noopener noreferrer"}},[e._v("ClickHouse"),t("OutboundLink")],1),e._v(".")]),e._v(" "),t("p",[e._v("Refers to "),t("RouterLink",{attrs:{to:"/dev/design.html"}},[e._v("design")]),e._v(" for how it works.")],1),e._v(" "),t("h2",{attrs:{id:"features"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#features"}},[e._v("#")]),e._v(" Features")]),e._v(" "),t("ul",[t("li",[e._v("Uses native ClickHouse client-server TCP protocol, with higher performance than HTTP.")]),e._v(" "),t("li",[e._v("Easy to use and deploy, you don't need write any hard code, just care about the configuration file")]),e._v(" "),t("li",[e._v("Support multiple parsers: fastjson(recommended), gjson, csv.")]),e._v(" "),t("li",[e._v("Support multiple Kafka client: kafka-go(recommended), sarama.")]),e._v(" "),t("li",[e._v("Support multiple Kafka security mechanisms: SSL, SASL/PLAIN, SASL/SCRAM, SASL/GSSAPI and combinations of them.")]),e._v(" "),t("li",[e._v("Support multiple sinker tasks, each runs on parallel.")]),e._v(" "),t("li",[e._v("Support multiple kafka and ClickHouse clusters.")]),e._v(" "),t("li",[e._v("Bulk insert (by config "),t("code",[e._v("bufferSize")]),e._v(" and "),t("code",[e._v("flushInterval")]),e._v(").")]),e._v(" "),t("li",[e._v("Parse messages concurrently.")]),e._v(" "),t("li",[e._v("Write batches concurrently.")]),e._v(" "),t("li",[e._v("Every batch is routed to a determined clickhouse shard. Exit if loop write fail.")]),e._v(" "),t("li",[e._v("Custom sharding policy (by config "),t("code",[e._v("shardingKey")]),e._v(" and "),t("code",[e._v("shardingPolicy")]),e._v(").")]),e._v(" "),t("li",[e._v("Tolerate replica single-point-failure.")]),e._v(" "),t("li",[e._v("At least once delivery guarantee.")]),e._v(" "),t("li",[e._v("Dynamic config management with Nacos.")])]),e._v(" "),t("h2",{attrs:{id:"supported-data-types"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#supported-data-types"}},[e._v("#")]),e._v(" Supported data types")]),e._v(" "),t("ul",[t("li",[e._v("[x] UInt8, UInt16, UInt32, UInt64, Int8, Int16, Int32, Int64")]),e._v(" "),t("li",[e._v("[x] Float32, Float64")]),e._v(" "),t("li",[e._v("[x] String")]),e._v(" "),t("li",[e._v("[x] FixedString")]),e._v(" "),t("li",[e._v("[x] Date, DateTime, DateTime64 (custom layout parser)")]),e._v(" "),t("li",[e._v("[x] Array(UInt8, UInt16, UInt32, UInt64, Int8, Int16, Int32, Int64)")]),e._v(" "),t("li",[e._v("[x] Array(Float32, Float64)")]),e._v(" "),t("li",[e._v("[x] Array(String)")]),e._v(" "),t("li",[e._v("[x] Array(FixedString)")]),e._v(" "),t("li",[e._v("[x] Nullable")]),e._v(" "),t("li",[e._v("[x] "),t("a",{attrs:{href:"https://www.elastic.co/guide/en/elasticsearch/reference/current/date.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("ElasticDateTime"),t("OutboundLink")],1),e._v(" => Int64 (2019-12-16T12:10:30Z => 1576498230)")])]),e._v(" "),t("h2",{attrs:{id:"configuration"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#configuration"}},[e._v("#")]),e._v(" Configuration")]),e._v(" "),t("p",[e._v("Refers to how "),t("a",{attrs:{href:"./go.test.sh"}},[e._v("integration test")]),e._v(" use the "),t("a",{attrs:{href:"./docker/config.json"}},[e._v("example config")]),e._v(".\nAlso refers to "),t("a",{attrs:{href:"./config/config.go"}},[e._v("code")]),e._v(" for all config items.")]),e._v(" "),t("h3",{attrs:{id:"kafka-encryption"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-encryption"}},[e._v("#")]),e._v(" Kafka Encryption")]),e._v(" "),t("p",[e._v("clickhouse_sinker supports following encryption mechanisms:")]),e._v(" "),t("ul",[t("li",[e._v("No encryption")])]),e._v(" "),t("p",[e._v("An example kafka config:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('    "kfk1": {\n      "brokers": "192.168.31.64:9092",\n      "@version": "Required if you use sarama. It\'s the the Kafka server version.",\n      "version": "2.2.1"\n    }\n')])])]),t("ul",[t("li",[e._v("Encryption using SSL")])]),e._v(" "),t("p",[e._v("An example kafka config:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('    "kfk2": {\n      "brokers": "192.168.31.64:9093",\n      "version": "2.2.1",\n      "tls": {\n        "enable": true,\n        "@caCertFiles": "Required. It\'s the CA certificate with which Kafka brokers certs be signed. This cert is added to kafka.client.truststore.jks which kafka-console-consumer.sh uses",\n        "caCertFiles": "/etc/security/ca-cert",\n        "@insecureSkipVerify": "Whether disable broker FQDN verification. Set it to `true` if kafka-console-consumer.sh uses `ssl.endpoint.identification.algorithm=`.",\n        "insecureSkipVerify": true\n      }\n    }\n')])])]),t("p",[e._v("FYI. "),t("code",[e._v("kafka-console-consumer.sh")]),e._v(" works as the following setup:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("$ cat config/SSL_NOAUTH_client.properties\nsecurity.protocol=SSL\nssl.truststore.location=/etc/security/kafka.client.truststore.jks\nssl.truststore.password=123456\nssl.endpoint.identification.algorithm=\n\n$ bin/kafka-console-consumer.sh --bootstrap-server 192.168.31.64:9094 --topic sunshine --group test-consumer-group --from-beginning --consumer.config config/SSL_NOAUTH_client.properties\n")])])]),t("p",[e._v("Please follow "),t("a",{attrs:{href:"https://kafka.apache.org/documentation/#security_ssl",target:"_blank",rel:"noopener noreferrer"}},[t("code",[e._v("Kafka SSL setup")]),t("OutboundLink")],1),e._v(". Use "),t("code",[e._v("-keyalg RSA")]),e._v(" when you create the broker keystore, otherwise there will be no cipher suites in common between the keystore and those Golang supports. See "),t("a",{attrs:{href:"https://github.com/Shopify/sarama/issues/643#issuecomment-216839760",target:"_blank",rel:"noopener noreferrer"}},[e._v("this"),t("OutboundLink")],1),e._v(" for reference.")]),e._v(" "),t("h3",{attrs:{id:"kafka-authentication"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-authentication"}},[e._v("#")]),e._v(" Kafka Authentication")]),e._v(" "),t("p",[e._v("clickhouse_sinker support following following authentication mechanisms:")]),e._v(" "),t("ul",[t("li",[e._v("No authentication")])]),e._v(" "),t("p",[e._v("An example kafka config:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('    "kfk1": {\n      "brokers": "192.168.31.64:9092",\n      "@version": "Required if you use sarama. It\'s the the Kafka server version.",\n      "version": "2.2.1"\n    }\n')])])]),t("ul",[t("li",[e._v("SASL/PLAIN")])]),e._v(" "),t("p",[e._v("An example kafka config:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('    "kfk3": {\n      "brokers": "192.168.31.64:9094",\n      "version": "2.2.1",\n      "sasl": {\n        "enable": true,\n        "mechanism": "PLAIN",\n        "username": "alice",\n        "password": "alice-secret"\n      }\n    }\n')])])]),t("p",[e._v("FYI. Java clients work with the following setup:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('$ cat config/PLAINTEXT_PLAIN_client.properties\nsecurity.protocol=SASL_PLAINTEXT\nsasl.kerberos.service.name=kafka\nsasl.mechanism=PLAIN\nsasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="alice" password="alice-secret";\n\n$ bin/kafka-console-producer.sh --broker-list 192.168.31.64:9094 --topic sunshine --producer.config config/PLAINTEXT_PLAIN_client.properties\n\n$ bin/kafka-console-consumer.sh --bootstrap-server 192.168.31.64:9094 --topic sunshine --group test-consumer-group --from-beginning --consumer.config config/PLAINTEXT_PLAIN_client.properties\n')])])]),t("ul",[t("li",[e._v("SASL/SCRAM")])]),e._v(" "),t("p",[e._v("An example kafka config:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('    "kfk4": {\n      "brokers": "192.168.31.64:9094",\n      "version": "2.2.1",\n      "sasl": {\n        "enable": true,\n        "@mechanism": "SCRAM-SHA-256 or SCRAM-SHA-512",\n        "mechanism": "SCRAM-SHA-256",\n        "username": "alice",\n        "password": "alice-secret"\n      }\n    }\n')])])]),t("p",[e._v("FYI. Java clients work with the following setup:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('$ cat config/PLAINTEXT_SCRAM_client.properties\nsecurity.protocol=SASL_PLAINTEXT\nsasl.kerberos.service.name=kafka\nsasl.mechanism=SCRAM-SHA-256\nsasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="alice" password="alice-secret";\n\n$ bin/kafka-console-producer.sh --broker-list 192.168.31.64:9094 --topic sunshine --producer.config config/PLAINTEXT_SCRAM_client.properties\n\n$ bin/kafka-console-consumer.sh --bootstrap-server 192.168.31.64:9094 --topic sunshine --group test-consumer-group --from-beginning --consumer.config config/PLAINTEXT_SCRAM_client.properties\n')])])]),t("ul",[t("li",[e._v("SASL/GSSAPI(Kerberos)")])]),e._v(" "),t("p",[e._v("An example kafka config:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('    "kfk5": {\n      "brokers": "192.168.31.64:9094",\n      "version": "2.2.1",\n      "sasl": {\n        "enable": true,\n        "mechanism": "GSSAPI",\n        "gssapi": {\n          "@authtype": "1 - Username and password, 2 - Keytab",\n          "authtype": 2,\n          "keytabpath": "/etc/security/mmmtest.keytab",\n          "kerberosconfigpath": "/etc/krb5.conf",\n          "servicename": "kafka",\n          "@username": "`principal` consists of `username` `@` `realm`",\n          "username": "mmm",\n          "realm": "ALANWANG.COM"\n        }\n      }\n    }\n')])])]),t("p",[e._v("FYI. Java clients work with the following setup:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('$ cat config/PLAINTEXT_GSSAPI_client.properties\nsecurity.protocol=SASL_PLAINTEXT\nsasl.kerberos.service.name=kafka\nsasl.mechanism=GSSAPI\nsasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true debug=true keyTab="/etc/security/mmmtest.keytab" principal="mmm@ALANWANG.COM";\n\n$ bin/kafka-console-producer.sh --broker-list 192.168.31.64:9094 --topic sunshine --producer.config config/PLAINTEXT_GSSAPI_client.properties\n\n$ bin/kafka-console-consumer.sh --bootstrap-server 192.168.31.64:9094 --topic sunshine --group test-consumer-group --from-beginning --consumer.config config/PLAINTEXT_GSSAPI_client.properties\n')])])]),t("p",[e._v("Kerberos setup is complex. Please ensure "),t("a",{attrs:{href:"https://docs.cloudera.com/runtime/7.2.1/kafka-managing/topics/kafka-manage-cli-consumer.html",target:"_blank",rel:"noopener noreferrer"}},[t("code",[e._v("kafka-console-consumer.sh")]),t("OutboundLink")],1),e._v(" Kerberos keytab authentication work STRICTLY FOLLOW "),t("a",{attrs:{href:"https://stackoverflow.com/questions/48744660/kafka-console-consumer-with-kerberos-authentication/49140414#49140414",target:"_blank",rel:"noopener noreferrer"}},[e._v("this article"),t("OutboundLink")],1),e._v(", then test "),t("code",[e._v("clickhouse_sinker")]),e._v(" Kerberos authentication on the SAME machine which "),t("code",[e._v("kafka-console-consumer.sh")]),e._v(" runs. I tested sarama Kerberos authentication against Kafka "),t("a",{attrs:{href:"https://archive.apache.org/dist/kafka/2.2.1/kafka_2.11-2.2.1.tgz",target:"_blank",rel:"noopener noreferrer"}},[e._v("2.2.1"),t("OutboundLink")],1),e._v(". Not sure other Kafka versions work.")]),e._v(" "),t("h3",{attrs:{id:"sharding-policy"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#sharding-policy"}},[e._v("#")]),e._v(" Sharding Policy")]),e._v(" "),t("p",[e._v("Every message is routed to a determined ClickHouse shard.")]),e._v(" "),t("p",[e._v("By default, the shard number is caculated by "),t("code",[e._v("(kafka_offset/roundup(batch_size))%clickhouse_shards")]),e._v(", where "),t("code",[e._v("roundup()")]),e._v(" round upward an unsigned integer to the the nearest 2^n.")]),e._v(" "),t("p",[e._v("This above expression can be customized with "),t("code",[e._v("shardingKey")]),e._v(" and "),t("code",[e._v("shardingPolicy")]),e._v(". "),t("code",[e._v("shardingKey")]),e._v(" value is a column name. "),t("code",[e._v("shardingPolicy")]),e._v(" value could be:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("stripe,<size>")]),e._v(". This requires "),t("code",[e._v("shardingKey")]),e._v(" be a numeric-like (bool, int, float, date etc.) column. The expression is "),t("code",[e._v("(uint64(shardingKey)/stripe_size)%clickhouse_shards")]),e._v(".")]),e._v(" "),t("li",[t("code",[e._v("hash")]),e._v(". This requires "),t("code",[e._v("shardingKey")]),e._v(" be a string-like column. The hash function used internally is "),t("a",{attrs:{href:"https://github.com/cespare/xxhash",target:"_blank",rel:"noopener noreferrer"}},[e._v("xxHash64"),t("OutboundLink")],1),e._v(". The expression is "),t("code",[e._v("xxhash64(string(shardingKey))%clickhouse_shards")]),e._v(".")])]),e._v(" "),t("h2",{attrs:{id:"configuration-management"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#configuration-management"}},[e._v("#")]),e._v(" Configuration Management")]),e._v(" "),t("p",[e._v("The precedence of config items:")]),e._v(" "),t("ul",[t("li",[e._v("CLI parameters > env variables")]),e._v(" "),t("li",[e._v("Nacos > Consul > Local Config File > Local Config Dir")])]),e._v(" "),t("h3",{attrs:{id:"nacos"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#nacos"}},[e._v("#")]),e._v(" Nacos")]),e._v(" "),t("p",[e._v("Sinker is able to register with Nacos, get and apply config changes dynamically without restart the whole process.\nControled by:")]),e._v(" "),t("ul",[t("li",[e._v("CLI parameters: "),t("code",[e._v("nacos-register-enable, nacos-addr, nacos-namespace-id, nacos-group, nacos-username, nacos-password")])]),e._v(" "),t("li",[e._v("env variables: "),t("code",[e._v("NACOS_REGISTER_ENABLE, NACOS_ADDR, NACOS_NAMESPACE_ID, NACOS_GROUP, NACOS_USERNAME, NACOS_PASSWORD")])])]),e._v(" "),t("h3",{attrs:{id:"consul"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#consul"}},[e._v("#")]),e._v(" Consul")]),e._v(" "),t("p",[e._v("Currently sinker is able to register with Consul, but unable to get config.\nControled by:")]),e._v(" "),t("ul",[t("li",[e._v("CLI parameters: "),t("code",[e._v("consul-register-enable, consul-addr, consul-deregister-critical-services-after")])]),e._v(" "),t("li",[e._v("env variables: "),t("code",[e._v("CONSUL_REGISTER_ENABLE, CONSUL_ADDR, CONSUL_DEREGISTER_CRITICAL_SERVICES_AFTER")])])]),e._v(" "),t("h3",{attrs:{id:"local-files"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#local-files"}},[e._v("#")]),e._v(" Local Files")]),e._v(" "),t("p",[e._v("Currently sinker is able to parse local config files at startup, but unable to detect file changes.\nControled by:")]),e._v(" "),t("ul",[t("li",[e._v("CLI parameters: "),t("code",[e._v("local-cfg-file, local-cfg-dir")])]),e._v(" "),t("li",[e._v("env variables: "),t("code",[e._v("LOCAL_CFG_FILE, LOCAL_CFG_DIR")])])]),e._v(" "),t("h2",{attrs:{id:"prometheus-metrics"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#prometheus-metrics"}},[e._v("#")]),e._v(" Prometheus Metrics")]),e._v(" "),t("p",[e._v("All metrics are defined in "),t("code",[e._v("statistics.go")]),e._v(". You can create Grafana dashboard for clickhouse_sinker by importing the template "),t("code",[e._v("clickhouse_sinker-dashboard.json")]),e._v(".")]),e._v(" "),t("ul",[t("li",[e._v("Pull with prometheus")])]),e._v(" "),t("p",[e._v("Metrics are exposed at "),t("code",[e._v("http://ip:port/metrics")]),e._v(". IP is the outbound IP of this machine. Port is from CLI "),t("code",[e._v("--http-port")]),e._v(" or env "),t("code",[e._v("HTTP_PORT")]),e._v(".")]),e._v(" "),t("p",[e._v("Sinker registers with Nacos if CLI "),t("code",[e._v("--consul-register-enable")]),e._v(" or env "),t("code",[e._v("CONSUL_REGISTER_ENABLE")]),e._v(" is present. However Prometheus is "),t("a",{attrs:{href:"https://github.com/alibaba/nacos/issues/1032",target:"_blank",rel:"noopener noreferrer"}},[e._v("unable"),t("OutboundLink")],1),e._v(" to obtain dynamic service list from nacos server.")]),e._v(" "),t("ul",[t("li",[e._v("Push to promethues")])]),e._v(" "),t("p",[e._v("If CLI "),t("code",[e._v("--metric-push-gateway-addrs")]),e._v(" or env "),t("code",[e._v("METRIC_PUSH_GATEWAY_ADDRS")]),e._v(" (a list of comma-separated urls) is present, metrics are pushed to one of given URLs regualarly.")]),e._v(" "),t("h2",{attrs:{id:"extending"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#extending"}},[e._v("#")]),e._v(" Extending")]),e._v(" "),t("p",[e._v("There are several abstract interfaces which you can implement to support more message format, message queue and config management mechanism.")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("type Parser interface {\n\tParse(bs []byte) model.Metric\n}\n\ntype Inputer interface {\n\tInit(cfg *config.Config, taskName string, putFn func(msg model.InputMessage)) error\n\tRun(ctx context.Context)\n\tStop() error\n\tCommitMessages(ctx context.Context, message *model.InputMessage) error\n}\n\n// RemoteConfManager can be implemented by many backends: Nacos, Consul, etcd, ZooKeeper...\ntype RemoteConfManager interface {\n\tInit(properties map[string]interface{}) error\n\t// Register this instance, and keep-alive via heartbeat.\n\tRegister(ip string, port int) error\n\tDeregister(ip string, port int) error\n\t// GetInstances fetchs healthy instances.\n\t// Mature service-discovery solutions(Nacos, Consul etc.) have client side cache\n\t// so that frequent invoking of GetInstances() and GetGlobalConfig() don't harm.\n\tGetInstances() (instances []Instance, err error)\n\t// GetConfig fetchs the config. The manager shall not reference the returned Config object after call.\n\tGetConfig() (conf *Config, err error)\n\t// PublishConfig publishs the config. The manager shall not reference the passed Config object after call.\n\tPublishConfig(conf *Config) (err error)\n}\n\n")])])]),t("h2",{attrs:{id:"why-not-kafka-engine-built-in-clickhouse"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#why-not-kafka-engine-built-in-clickhouse"}},[e._v("#")]),e._v(" Why not "),t("a",{attrs:{href:"https://clickhouse.tech/docs/en/engines/table-engines/integrations/kafka/",target:"_blank",rel:"noopener noreferrer"}},[t("code",[e._v("Kafka Engine")]),t("OutboundLink")],1),e._v(" built in ClickHouse?")]),e._v(" "),t("ul",[t("li",[e._v("My experience indicates "),t("code",[e._v("Kafka Engine")]),e._v(" is complicated, buggy and hard to debug.")]),e._v(" "),t("li",[t("code",[e._v("Kafka Engine")]),e._v(" runs inside the db process, lowers the database stability. On the other side, "),t("a",{attrs:{href:"https://www.vertica.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Vertica"),t("OutboundLink")],1),e._v("'s official kafka importer is separated with the database server.")]),e._v(" "),t("li",[t("code",[e._v("Kafka Engine")]),e._v(" doesn't support custom sharding policy.")]),e._v(" "),t("li",[e._v("Neither "),t("code",[e._v("Kafka Engine")]),e._v(" nor clickhouse_sinker support exactly-once.")])]),e._v(" "),t("h2",{attrs:{id:"kafka-compatibility"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-compatibility"}},[e._v("#")]),e._v(" Kafka Compatibility")]),e._v(" "),t("p",[e._v("Kafka broker "),t("a",{attrs:{href:"https://kafka.apache.org/protocol#api_versions",target:"_blank",rel:"noopener noreferrer"}},[e._v("exposes versions of various APIs it supports since 0.10.0.0"),t("OutboundLink")],1),e._v(".")]),e._v(" "),t("h3",{attrs:{id:"kafka-go"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-go"}},[e._v("#")]),e._v(" Kafka-go")]),e._v(" "),t("ul",[t("li",[e._v("Kafka-go "),t("a",{attrs:{href:"https://github.com/segmentio/kafka-go/blob/c66d8ca149e7f1a7905b47a60962745ceb08a6a9/conn.go#L209",target:"_blank",rel:"noopener noreferrer"}},[e._v("negotiate it's protocol Version"),t("OutboundLink")],1),e._v(".")]),e._v(" "),t("li",[e._v("Kafka-go "),t("a",{attrs:{href:"https://github.com/segmentio/kafka-go/issues/237",target:"_blank",rel:"noopener noreferrer"}},[e._v("doesn't support Kerberos authentication"),t("OutboundLink")],1),e._v(".")])]),e._v(" "),t("h3",{attrs:{id:"sarama"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#sarama"}},[e._v("#")]),e._v(" Sarama")]),e._v(" "),t("ul",[t("li",[e._v("Sarama guarantees compatibility "),t("a",{attrs:{href:"https://github.com/Shopify/sarama/blob/master/README.md#compatibility-and-api-stability",target:"_blank",rel:"noopener noreferrer"}},[e._v("with Kafka 2.4 through 2.6"),t("OutboundLink")],1),e._v(".")]),e._v(" "),t("li",[e._v("Sarama "),t("a",{attrs:{href:"https://github.com/Shopify/sarama/issues/1732",target:"_blank",rel:"noopener noreferrer"}},[e._v("has tied it's protocol usage to the Version field in Config"),t("OutboundLink")],1),e._v(".")])]),e._v(" "),t("h3",{attrs:{id:"conclusion"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#conclusion"}},[e._v("#")]),e._v(" Conclusion")]),e._v(" "),t("ul",[t("li",[e._v("Neither Kafka-go nor sarama is mature as Java clients. You need to try both if clickhouse_sinker fails to connect with Kafka.")]),e._v(" "),t("li",[e._v("Our experience is sarama can't work well with new kafka server if set its "),t("code",[e._v("Config.Version")]),e._v(' to "0.11.0.0". So we suggest '),t("code",[e._v("KafkaConfig.Version")]),e._v(" in clickhouse_sinker config matchs the Kafka server.")])])])}),[],!1,null,null,null);a.default=s.exports}}]);